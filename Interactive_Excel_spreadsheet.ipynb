{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Installing Packages"
      ],
      "metadata": {
        "id": "NgMlUH4IBCOI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U transformers\n",
        "!pip install sentencepiece\n",
        "!pip install accelerate\n",
        "!pip install bitsandbytes"
      ],
      "metadata": {
        "id": "bgRskiXHA_r_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing dependencies"
      ],
      "metadata": {
        "id": "nvh-V3W4BKIt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-xLQTcl1_xgG"
      },
      "outputs": [],
      "source": [
        "from langchain.document_loaders import CSVLoader\n",
        "from langchain.indexes import VectorstoreIndexCreator\n",
        "from langchain.chains import RetrievalQA\n",
        "import pandas as pd\n",
        "import os\n",
        "from transformers import LlamaTokenizer, LlamaForCausalLM, GenerationConfig, pipeline\n",
        "from langchain.llms import HuggingFacePipeline\n",
        "from langchain import PromptTemplate, LLMChain\n",
        "import torch\n",
        "from transformers import BitsAndBytesConfig\n",
        "\n",
        "\n",
        "csv_data = CSVLoader(file_path='-Your-filepath-')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initalizing model functionality"
      ],
      "metadata": {
        "id": "mKVGqixnCfcK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#defining the model\n",
        "quantization_config = BitsAndBytesConfig(llm_int4_enable_fp32_cpu_offload=True)\n",
        "\n",
        "tokenizer = LlamaTokenizer.from_pretrained(\"chavinlo/alpaca-native\")\n",
        "\n",
        "base_model = LlamaForCausalLM.from_pretrained(\n",
        "    \"chavinlo/alpaca-native\",\n",
        "    load_in_4bit=True,\n",
        "    quantization_config=quantization_config,\n",
        "    offload_folder=\"offload\",\n",
        "    torch_dtype=torch.float16,\n",
        "    device_map='auto',\n",
        ")\n",
        "\n",
        "base_model.tie_weights()"
      ],
      "metadata": {
        "id": "_N3Yiy0-BaTx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipe = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=base_model,\n",
        "    tokenizer=tokenizer,\n",
        "    max_length=256,\n",
        "    temperature=0.6,\n",
        "    top_p=0.95,\n",
        "    repetition_penalty=1.2\n",
        ")\n",
        "\n",
        "local_llm = HuggingFacePipeline(pipeline=pipe)"
      ],
      "metadata": {
        "id": "XLn5z9tjBgAA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index_creator = VectorstoreIndexCreator()\n",
        "docsearch = index_creator.from_loaders([csv_data])"
      ],
      "metadata": {
        "id": "_e9UqU0IBoOP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain = RetrievalQA.from_chain_type(llm=local_llm, chain_type=\"stuff\", retriever=docsearch.vectorstore.as_retriever(), input_key=\"question\")"
      ],
      "metadata": {
        "id": "L3sR5ZvfBxrr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Implemented usage of model\n",
        "can be implemented in a similar way for projects with UI\n"
      ],
      "metadata": {
        "id": "UfqpQuc2CkNJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"-own query-\"\n",
        "response = chain({\"question\": query})\n",
        "print(response['result'])"
      ],
      "metadata": {
        "id": "-FSdYKLoCPG1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}